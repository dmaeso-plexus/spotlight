{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect nearest neighbors with Annoy and remove duplicates\n",
    "\n",
    "We use the [Annoy library](https://github.com/spotify/annoy) to detect nearest neighbors and Spotlight to inspect and remove duplicates.\n",
    "\n",
    "More information about this play can be found in the Spotlight documentation: [Detect and remove duplicates](https://renumics.com/docs/playbook/duplicates-annoy)\n",
    "\n",
    "For more data-centric AI workflows, check out our [Awesome Open Data-centric AI](https://github.com/Renumics/awesome-open-data-centric-ai) list on Github."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tldr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install required packages with PIP\n",
    "\n",
    "!pip install renumics-spotlight datasets annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Play as copy-n-paste functions\n",
    "\n",
    "import datasets\n",
    "from renumics import spotlight\n",
    "from annoy import AnnoyIndex\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "def nearest_neighbor_annoy(\n",
    "    df, embedding_name=\"embedding\", threshold=0.3, tree_size=100\n",
    "):\n",
    "    embs = df[embedding_name]\n",
    "\n",
    "    t = AnnoyIndex(len(embs[0]), \"angular\")\n",
    "\n",
    "    for idx, x in enumerate(embs):\n",
    "        t.add_item(idx, x)\n",
    "\n",
    "    t.build(tree_size)\n",
    "\n",
    "    images = df[\"image\"]\n",
    "\n",
    "    df_nn = pd.DataFrame()\n",
    "\n",
    "    nn_id = [t.get_nns_by_item(i, 2)[1] for i in range(len(embs))]\n",
    "    df_nn[\"nn_id\"] = nn_id\n",
    "    df_nn[\"nn_image\"] = [images[i] for i in nn_id]\n",
    "    df_nn[\"nn_distance\"] = [t.get_distance(i, nn_id[i]) for i in range(len(embs))]\n",
    "    df_nn[\"nn_flag\"] = df_nn.nn_distance < threshold\n",
    "\n",
    "    return df_nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-step example on CIFAR-100\n",
    "\n",
    "### Load CIFAR-100 from Huggingface hub and convert it to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"renumics/cifar100-enriched\", split=\"all\")\n",
    "\n",
    "df = dataset.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute nearest neighbors including distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nn = nearest_neighbor_annoy(df)\n",
    "df = pd.concat([df, df_nn], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect and remove duplicates with Spotlight\n",
    "\n",
    "> ⚠️ Running Spotlight in Colab currently has severe limitations (slow, no similarity map, no layouts) due to Colab restrictions (e.g. no websocket support). Run the notebook locally for the full Spotlight experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_show = df.drop(columns=[\"embedding\", \"probabilities\"])\n",
    "\n",
    "\n",
    "# handle google colab differently\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # visualization in Google Colab only works in chrome and does not support websockets, we need some hacks to visualize something\n",
    "    df_show = df_show[:10000]\n",
    "    df_show[\"embx\"] = [emb[0] for emb in df_show[\"embedding_reduced\"]]\n",
    "    df_show[\"emby\"] = [emb[1] for emb in df_show[\"embedding_reduced\"]]\n",
    "    port = 50123\n",
    "    layout_url = \"https://raw.githubusercontent.com/Renumics/spotlight/main/playbook/veteran/duplicates_annoy_colab.json\"\n",
    "    response = requests.get(layout_url)\n",
    "    layout = spotlight.layout.nodes.Layout(**json.loads(response.text))\n",
    "    spotlight.show(\n",
    "        df_show,\n",
    "        port=port,\n",
    "        dtype={\"image\": spotlight.Image, \"nn_image\": spotlight.Image},\n",
    "        layout=layout,\n",
    "    )\n",
    "    from google.colab.output import eval_js  # type: ignore\n",
    "\n",
    "    print(str(eval_js(f\"google.colab.kernel.proxyPort({port}, {{'cache': true}})\")))\n",
    "\n",
    "else:\n",
    "    df_show = df.drop(columns=[\"embedding\", \"probabilities\"])\n",
    "    layout_url = \"https://raw.githubusercontent.com/Renumics/spotlight/main/playbook/veteran/duplicates_annoy.json\"\n",
    "    response = requests.get(layout_url)\n",
    "    layout = spotlight.layout.nodes.Layout(**json.loads(response.text))\n",
    "    spotlight.show(\n",
    "        df_show,\n",
    "        dtype={\n",
    "            \"image\": spotlight.Image,\n",
    "            \"nn_image\": spotlight.Image,\n",
    "            \"embedding_reduced\": spotlight.Embedding,\n",
    "        },\n",
    "        layout=layout,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
